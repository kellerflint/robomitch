{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aebc49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\kflin/.cache\\torch\\hub\\snakers4_silero-vad_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker ID to Name Mapping:\n",
      "188496350789369856 -> Ethan\n",
      "210818185623109638 -> Luke\n",
      "274340078015217666 -> Keller\n",
      "293246585674924035 -> Mitch\n",
      "332042555497644033 -> Seth\n",
      "ðŸ§¹ Processing 4052 audio files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4052/4052 [09:38<00:00,  7.01it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All files processed!\n",
      "ðŸŽ™ï¸ Valid speech clips saved: 3023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import save\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set VAD thread safety\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "# Load Silero VAD\n",
    "model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad')\n",
    "(get_speech_timestamps, _, read_audio, _, _) = utils\n",
    "\n",
    "# Read speaker mapping\n",
    "mapping_file = \"../recordings/mapping.txt\"\n",
    "id_to_name = {}\n",
    "with open(mapping_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        discord_id, name = line.strip().split(\"=\")\n",
    "        id_to_name[discord_id] = name\n",
    "\n",
    "print(\"Speaker ID to Name Mapping:\")\n",
    "for discord_id, name in id_to_name.items():\n",
    "    print(f\"{discord_id} -> {name}\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(\"clean_chunks\", exist_ok=True)\n",
    "\n",
    "# Process all audio files\n",
    "data_root = \"../recordings/async\"\n",
    "speaker_audio_dict = {}\n",
    "\n",
    "# Count all .wav files first to get total length for progress bar\n",
    "all_wav_files = []\n",
    "for speaker_folder in os.listdir(data_root):\n",
    "    full_path = os.path.join(data_root, speaker_folder)\n",
    "    if os.path.isdir(full_path):\n",
    "        all_wav_files += glob.glob(os.path.join(full_path, \"*.mp3\"))\n",
    "\n",
    "print(f\"ðŸ§¹ Processing {len(all_wav_files)} audio files...\")\n",
    "\n",
    "for wav_file in tqdm(all_wav_files, desc=\"Processing\"):\n",
    "    try:\n",
    "        # Extract speaker ID from path\n",
    "        speaker_id = os.path.basename(os.path.dirname(wav_file)).split(\"_\")[0]\n",
    "        speaker_name = id_to_name.get(speaker_id, speaker_id)\n",
    "\n",
    "        # Prepare output path\n",
    "        output_dir = os.path.join(\"clean_chunks\", speaker_name)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Read and VAD\n",
    "        wav = read_audio(wav_file, sampling_rate=16000)\n",
    "        speech_timestamps = get_speech_timestamps(wav, model, return_seconds=True)\n",
    "\n",
    "        for i, segment in enumerate(speech_timestamps):\n",
    "            start = int(segment['start'] * 16000)\n",
    "            end = int(segment['end'] * 16000)\n",
    "            chunk = wav[start:end]\n",
    "\n",
    "            if (end - start) / 16000 < 1.0:  # Skip too-short clips\n",
    "                continue\n",
    "\n",
    "            base_name = os.path.splitext(os.path.basename(wav_file))[0]\n",
    "            chunk_filename = f\"{base_name}_chunk{i}.wav\"\n",
    "            chunk_path = os.path.join(output_dir, chunk_filename)\n",
    "            save(chunk_path, chunk.unsqueeze(0), 16000)\n",
    "\n",
    "            speaker_audio_dict[chunk_path] = speaker_name\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {wav_file}: {e}\")\n",
    "\n",
    "print(\"âœ… All files processed!\")\n",
    "print(f\"ðŸŽ™ï¸ Valid speech clips saved: {len(speaker_audio_dict)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
